{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4vy6Y4I4QTv",
        "outputId": "436a9208-e425-495f-ee41-298d07769610"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub\n",
        "!apt-get install ffmpeg\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLyEvW8F4RFc",
        "outputId": "29adddb0-7bba-4ec4-e8a5-f7cbc332d9eb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1ElDd7pF-qxU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Define the input and output directories\n",
        "input_dir = \"/content/drive/My Drive/audio/marvin\"  # Replace with the path to your .m4a files\n",
        "output_dir = \"/content/drive/My Drive/sound/marvin\"  # Replace with the path to save .wav files\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Loop over all .m4a files in the input directory and convert them to .wav\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.endswith(\".m4a\"):\n",
        "        input_file = os.path.join(input_dir, filename)\n",
        "        output_file = os.path.join(output_dir, os.path.splitext(filename)[0] + \".wav\")\n",
        "\n",
        "        # Convert to .wav using pydub\n",
        "        print(f\"Converting {filename} to WAV format...\")\n",
        "        audio = AudioSegment.from_file(input_file, format=\"m4a\")\n",
        "        audio.export(output_file, format=\"wav\")\n",
        "        print(f\"Saved: {output_file}\")\n",
        "\n",
        "print(\"All files converted successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymWrlmND-4Jw",
        "outputId": "0e40eadb-1ceb-45c2-91df-f49346cdd1d9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting Recording (28).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (28).wav\n",
            "Converting Recording (27).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (27).wav\n",
            "Converting Recording (24).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (24).wav\n",
            "Converting Recording (25).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (25).wav\n",
            "Converting Recording (26).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (26).wav\n",
            "Converting Recording (23).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (23).wav\n",
            "Converting Recording (22).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (22).wav\n",
            "Converting Recording (2).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (2).wav\n",
            "Converting Recording (20).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (20).wav\n",
            "Converting Recording (21).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (21).wav\n",
            "Converting Recording (19).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (19).wav\n",
            "Converting Recording (18).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (18).wav\n",
            "Converting Recording (15).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (15).wav\n",
            "Converting Recording (16).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (16).wav\n",
            "Converting Recording (17).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (17).wav\n",
            "Converting Recording (13).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (13).wav\n",
            "Converting Recording (14).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (14).wav\n",
            "Converting Recording (11).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (11).wav\n",
            "Converting Recording (10).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (10).wav\n",
            "Converting Recording (12).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (12).wav\n",
            "Converting Recording (9).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (9).wav\n",
            "Converting Recording (7).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (7).wav\n",
            "Converting Recording (8).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (8).wav\n",
            "Converting Recording (6).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (6).wav\n",
            "Converting Recording.m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording.wav\n",
            "Converting Recording (4).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (4).wav\n",
            "Converting Recording (5).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (5).wav\n",
            "Converting Recording (29).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (29).wav\n",
            "Converting Recording (3).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (3).wav\n",
            "Converting Recording (30).m4a to WAV format...\n",
            "Saved: /content/drive/My Drive/sound/marvin/Recording (30).wav\n",
            "All files converted successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Preprocessing to convert waveforms to Mel Spectrograms\n",
        "class ToMelSpectrogram:\n",
        "    def __init__(self, n_mels=64, n_fft=1024, hop_length=512, fixed_length=128, sample_rate=16000):\n",
        "        self.transform = T.MelSpectrogram(n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
        "        self.fixed_length = fixed_length\n",
        "        self.sample_rate = sample_rate\n",
        "        self.max_length = sample_rate  # 1 second of audio\n",
        "\n",
        "    def __call__(self, waveform):\n",
        "        # Ensure the waveform is mono (1 channel)\n",
        "        if waveform.size(0) > 1:  # If the waveform has multiple channels, average them to mono\n",
        "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "        # Ensure the waveform is at least 1 second (or desired length)\n",
        "        if waveform.size(1) > self.max_length:\n",
        "            waveform = waveform[:, :self.max_length]  # Truncate the waveform\n",
        "        elif waveform.size(1) < self.max_length:\n",
        "            padding = self.max_length - waveform.size(1)\n",
        "            waveform = F.pad(waveform, (0, padding))  # Pad the waveform with zeros\n",
        "\n",
        "        # Convert the waveform to a Mel Spectrogram\n",
        "        mel_spec = self.transform(waveform)  # [n_mels, time]\n",
        "        mel_spec = mel_spec.squeeze(0)  # Remove channel dimension if necessary\n",
        "\n",
        "        # Ensure the spectrogram is exactly fixed_length in time dimension\n",
        "        if mel_spec.size(1) < self.fixed_length:\n",
        "            pad_size = self.fixed_length - mel_spec.size(1)\n",
        "            mel_spec = F.pad(mel_spec, (0, pad_size), \"constant\", 0)\n",
        "        else:\n",
        "            mel_spec = mel_spec[:, :self.fixed_length]\n",
        "\n",
        "        # Return the spectrogram with the channel dimension [1, n_mels, fixed_length]\n",
        "        return mel_spec.unsqueeze(0)\n",
        "\n",
        "\n",
        "# Custom dataset class\n",
        "class SpeechCommandsDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.commands = sorted(os.listdir(data_dir))\n",
        "        self.file_paths = []\n",
        "\n",
        "        for command in self.commands:\n",
        "            command_dir = os.path.join(data_dir, command)\n",
        "            if not os.path.isdir(command_dir):\n",
        "                continue\n",
        "            for filename in os.listdir(command_dir):\n",
        "                if filename.endswith('.wav'):\n",
        "                    self.file_paths.append((os.path.join(command_dir, filename), self.commands.index(command)))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path, label = self.file_paths[idx]\n",
        "        waveform, sample_rate = torchaudio.load(file_path)\n",
        "        if self.transform:\n",
        "            waveform = self.transform(waveform)\n",
        "        return waveform, label\n",
        "\n",
        "\n",
        "# Define the CNN model\n",
        "class CNNClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Use adaptive pooling to handle variable input sizes\n",
        "        self.adaptive_pool = nn.AdaptiveAvgPool2d((16, 8))\n",
        "\n",
        "        # Calculate the flattened size automatically\n",
        "        self.fc1 = nn.Linear(32 * 16 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "\n",
        "        # Use adaptive pooling to ensure the output size is always the same\n",
        "        x = self.adaptive_pool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, num_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        model.train()\n",
        "        for inputs, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)  # Pass the input to the CNN\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Loss: {running_loss/len(train_loader)}')\n",
        "\n",
        "    # Save the trained model weights after training\n",
        "    torch.save(model.state_dict(), 'model_weights.pth')\n",
        "    print(\"Model weights saved to 'model_weights.pth'\")\n",
        "\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "\n",
        "# Load and preprocess the dataset\n",
        "data_dir = '/content/drive/MyDrive/sound'\n",
        "transform = ToMelSpectrogram()\n",
        "dataset = SpeechCommandsDataset(data_dir, transform=transform)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "if len(dataset) > 0:\n",
        "    train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    # Create DataLoaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # Initialize and train the model\n",
        "    model = CNNClassifier(num_classes=len(dataset.commands))\n",
        "    train_model(model, train_loader)\n",
        "\n",
        "    # Evaluate the model\n",
        "    evaluate_model(model, test_loader)\n",
        "else:\n",
        "    print(\"Dataset is empty. Please check the directory and files.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xh-NFmXL7cq",
        "outputId": "f7df813d-cec5-41f1-83bb-7c80b813a626"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.788423458735148\n",
            "Epoch 2, Loss: 2.768233080705007\n",
            "Epoch 3, Loss: 2.7543912331263223\n",
            "Epoch 4, Loss: 2.702907125155131\n",
            "Epoch 5, Loss: 2.6357186436653137\n",
            "Epoch 6, Loss: 2.5578250686327615\n",
            "Epoch 7, Loss: 2.4688090682029724\n",
            "Epoch 8, Loss: 2.4048871199289956\n",
            "Epoch 9, Loss: 2.3478829065958657\n",
            "Epoch 10, Loss: 2.307185490926107\n",
            "Model weights saved to 'model_weights.pth'\n",
            "Accuracy: 20.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "# Path to the saved model weights\n",
        "model_weights_path = 'model_weights.pth'\n",
        "\n",
        "# Calculate the MD5 checksum\n",
        "def calculate_md5(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        data = file.read()\n",
        "        return hashlib.md5(data).hexdigest()\n",
        "\n",
        "# Get the checksum of the model weights file\n",
        "md5_checksum = calculate_md5(model_weights_path)\n",
        "print(f'MD5 Checksum for model_weights.pth: {md5_checksum}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDzXM0-rL761",
        "outputId": "2cc95037-9c2c-45c3-b644-941bcea31514"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MD5 Checksum for model_weights.pth: 672421f308a6cdef999632ebe4edcb3c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import hashlib\n",
        "\n",
        "# Path to the saved model weights\n",
        "model_weights_path = 'model_weights.pth'\n",
        "\n",
        "# Calculate the MD5 checksum\n",
        "def calculate_md5(file_path):\n",
        "    with open(file_path, 'rb') as file:\n",
        "        data = file.read()\n",
        "        return hashlib.md5(data).hexdigest()\n",
        "\n",
        "# Expected checksum value (this should be copied from your initial checksum calculation)\n",
        "expected_md5_checksum = '672421f308a6cdef999632ebe4edcb3c'\n",
        "\n",
        "# Get the current checksum of the model weights file\n",
        "current_md5_checksum = calculate_md5(model_weights_path)\n",
        "\n",
        "# Verify the checksum\n",
        "if current_md5_checksum == expected_md5_checksum:\n",
        "    print(f'Checksum verification passed. MD5 Checksum: {current_md5_checksum}')\n",
        "else:\n",
        "    print(f'Checksum verification failed. MD5 Checksum: {current_md5_checksum}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "og3UNAHYdQ9i",
        "outputId": "9e560a2c-7354-42fc-fda7-f56481bbebd2"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checksum verification passed. MD5 Checksum: 672421f308a6cdef999632ebe4edcb3c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8yPV52LRdakK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}